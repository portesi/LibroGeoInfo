\seccion{Esperanza, momentos y funciones generadoras}
\label{s:esperanzamomento}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\emph{introducci\'on...} %%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subseccion{Momentos de una distribuci\'on}


Una variable aleatoria continua $X$ tiene asociado un \emph{promedio} o \emph{media} (también llamado \emph{valor esperado o de expectación}) $\langle x\rangle$ que se obtiene pesando cada valor de $x$ con la probabilidad asociada a ese valor, $p(x)\,dx$, e integrando sobre el rango permitido de $x$: 
$$
\mu = E[X] = \langle x\rangle = \int_{\Omega} x \ p(x)\,dx
$$
si la integral existe. La \emph{esperanza} de la variable aleatoria $X$ representa el valor medio que puede tomar entre todos los eventos de una prueba. 

En general, si $X$ es una variable aleatoria, cualquier función $f(X)$ también lo es, y su valor de expectación, si existe, está dado por 
$$
E[f(X)] = \langle f(x)\rangle = \int_{\Omega} f(x) \ p(x)\,dx
$$
En particular, para el monomio $f(x)=x^r$ siendo $r\in\Nset$, se obtiene el $r$\emph{-ésimo momento (ordinario)} de $X$: 
$$
\nu_r \equiv \langle x^r\rangle = \int_{\Omega} x^r \ p(x)\,dx
$$
que tiene unidades de $[x]^r$. Se puede incluir el caso $r=0$, que corresponde a la condición de normalización: \ $\nu_0=\int_{\Omega}p(x) \,dx=1$. La media es el primer momento: $\nu_1=\langle x\rangle=\mu$. Típicamente, los primeros momentos son más relevantes que los de órdenes mayores, para la caracterización de una distribución. 
%% Analogía con Mecánica ...

Por ejemplo, para la distribución uniforme $p(x)=\frac{1}{b-a}$ en el intervalo $[a,b]$, resulta: \ $\nu_1=\langle x\rangle=\frac 12 (b+a)$, \ $\nu_2=\langle x^2\rangle=\frac 13 (b^2+ab+b^2)$, \ldots, $\nu_r=\frac{b^{r+1}-a[{r+1}}{(r+1)(b-a)}$. %%Simplificar. Ejercicio para otra distrib ?

Cuando  una pdf $p(x)$ tiene soporte (semi)infinito, %%
necesariamente la función $p$ debe tender a 0 cuando $|x|\rightarrow\infty$.  
Si $p(x)$ es \emph{de largo alcance}, en el sentido de que no cae a 0 suficientemente rápido con $x$ para $x$ grandes, algunos momentos pueden no existir. Por ejemplo, la distribución de probabilidad de Cauchy--Lorentz (o función de Breit--Wigner), dada por $p(x)=\frac{\gamma}{\pi} \frac{1}{\gamma^2+(x-x_0)^2}$ para $x\in(-\infty,\infty)$, con $\gamma>0$ y $x_0$ fijos, no tiene momentos finitos de orden $r\geq 1$. 
%%...

%%Figura: varias Lorentzianas. 

\hfill

En el caso de una variable aleatoria discreta $X$ que toma valores en $\Omega=\{x_1, \ldots, x_N\}$, la esperanza de la variable viene dada por 
$$
E[X] = \sum_{n=1}^N x_n \, p(x_n) . 
$$

....

....

\vspace{1.5pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subseccion{Funciones generatrices}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

....

\vspace{1.5pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%